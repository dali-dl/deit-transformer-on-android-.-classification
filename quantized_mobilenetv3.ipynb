{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nArguments for call are not valid.\nThe following variants are available:\n  \n  aten::tensor.float(float t, *, int? dtype=None, Device? device=None, bool requires_grad=False) -> (Tensor):\n  Argument t not provided.\n  \n  aten::tensor.int(int t, *, int? dtype=None, Device? device=None, bool requires_grad=False) -> (Tensor):\n  Argument t not provided.\n  \n  aten::tensor.bool(bool t, *, int? dtype=None, Device? device=None, bool requires_grad=False) -> (Tensor):\n  Argument t not provided.\n  \n  aten::tensor(t[] data, *, int? dtype=None, Device? device=None, bool requires_grad=False) -> (Tensor):\n  Could not match type int to List[t] in argument 'data': Cannot match List[t] to int.\n\nThe original call is:\n  File \"<ipython-input-1-5d88d5c8c2b9>\", line 233\n        # prob is not smalller than the threshold or not?\n        if torch.max(probs) < threshold:\n            return torch.tensor(data=-111)\n                   ~~~~~~~~~~~~ <--- HERE\n\n        return torch.argmax(probs)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-5d88d5c8c2b9>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    328\u001B[0m \u001B[0mmodel_tiny\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmobilenet_v3_large\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpretrained\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmobile_optimizer\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0moptimize_for_mobile\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 330\u001B[0;31m \u001B[0mts_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscript\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_tiny\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    331\u001B[0m \u001B[0moptimized_torchscript_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptimize_for_mobile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mts_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[0moptimized_torchscript_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"mobilenetv3_large.pt\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/jit/_script.py\u001B[0m in \u001B[0;36mscript\u001B[0;34m(obj, optimize, _frames_up, _rcb)\u001B[0m\n\u001B[1;32m    895\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    896\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mModule\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 897\u001B[0;31m         return torch.jit._recursive.create_script_module(\n\u001B[0m\u001B[1;32m    898\u001B[0m             \u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_recursive\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfer_methods_to_compile\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    899\u001B[0m         )\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/jit/_recursive.py\u001B[0m in \u001B[0;36mcreate_script_module\u001B[0;34m(nn_module, stubs_fn, share_types)\u001B[0m\n\u001B[1;32m    350\u001B[0m     \u001B[0mcheck_module_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    351\u001B[0m     \u001B[0mconcrete_type\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_module_concrete_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshare_types\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 352\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mcreate_script_module_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconcrete_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstubs_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    353\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    354\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mcreate_script_module_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconcrete_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstubs_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/jit/_recursive.py\u001B[0m in \u001B[0;36mcreate_script_module_impl\u001B[0;34m(nn_module, concrete_type, stubs_fn)\u001B[0m\n\u001B[1;32m    408\u001B[0m     \u001B[0;31m# Compile methods if necessary\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    409\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mconcrete_type\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mconcrete_type_store\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmethods_compiled\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 410\u001B[0;31m         \u001B[0mcreate_methods_and_properties_from_stubs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconcrete_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod_stubs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproperty_stubs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    411\u001B[0m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_emit_module_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcpp_module\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    412\u001B[0m         \u001B[0mconcrete_type_store\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmethods_compiled\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconcrete_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/jit/_recursive.py\u001B[0m in \u001B[0;36mcreate_methods_and_properties_from_stubs\u001B[0;34m(concrete_type, method_stubs, property_stubs)\u001B[0m\n\u001B[1;32m    302\u001B[0m     \u001B[0mproperty_rcbs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresolution_callback\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mproperty_stubs\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 304\u001B[0;31m     \u001B[0mconcrete_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_methods_and_properties\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mproperty_defs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproperty_rcbs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod_defs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod_rcbs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    305\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: \nArguments for call are not valid.\nThe following variants are available:\n  \n  aten::tensor.float(float t, *, int? dtype=None, Device? device=None, bool requires_grad=False) -> (Tensor):\n  Argument t not provided.\n  \n  aten::tensor.int(int t, *, int? dtype=None, Device? device=None, bool requires_grad=False) -> (Tensor):\n  Argument t not provided.\n  \n  aten::tensor.bool(bool t, *, int? dtype=None, Device? device=None, bool requires_grad=False) -> (Tensor):\n  Argument t not provided.\n  \n  aten::tensor(t[] data, *, int? dtype=None, Device? device=None, bool requires_grad=False) -> (Tensor):\n  Could not match type int to List[t] in argument 'data': Cannot match List[t] to int.\n\nThe original call is:\n  File \"<ipython-input-1-5d88d5c8c2b9>\", line 233\n        # prob is not smalller than the threshold or not?\n        if torch.max(probs) < threshold:\n            return torch.tensor(data=-111)\n                   ~~~~~~~~~~~~ <--- HERE\n\n        return torch.argmax(probs)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from functools import partial\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence\n",
    "\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "__all__ = [\"MobileNetV3\", \"mobilenet_v3_large\", \"mobilenet_v3_small\"]\n",
    "class ConvBNActivation(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_planes: int,\n",
    "        out_planes: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        groups: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        activation_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        dilation: int = 1,\n",
    "    ) -> None:\n",
    "        padding = (kernel_size - 1) // 2 * dilation\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if activation_layer is None:\n",
    "            activation_layer = nn.ReLU6\n",
    "        super().__init__(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, dilation=dilation, groups=groups,\n",
    "                      bias=False),\n",
    "            norm_layer(out_planes),\n",
    "            activation_layer(inplace=True)\n",
    "        )\n",
    "        self.out_channels = out_planes\n",
    "\n",
    "def _make_divisible(v: float, divisor: int, min_value: Optional[int] = None) -> int:\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "model_urls = {\n",
    "    \"mobilenet_v3_large\": \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\",\n",
    "    \"mobilenet_v3_small\": \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\",\n",
    "}\n",
    "\n",
    "\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    # Implemented as described at Figure 4 of the MobileNetV3 paper\n",
    "    def __init__(self, input_channels: int, squeeze_factor: int = 4):\n",
    "        super().__init__()\n",
    "        squeeze_channels = _make_divisible(input_channels // squeeze_factor, 8)\n",
    "        self.fc1 = nn.Conv2d(input_channels, squeeze_channels, 1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(squeeze_channels, input_channels, 1)\n",
    "\n",
    "    def _scale(self, input: Tensor, inplace: bool) -> Tensor:\n",
    "        scale = F.adaptive_avg_pool2d(input, 1)\n",
    "        scale = self.fc1(scale)\n",
    "        scale = self.relu(scale)\n",
    "        scale = self.fc2(scale)\n",
    "        return F.hardsigmoid(scale, inplace=inplace)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        scale = self._scale(input, True)\n",
    "        return scale * input\n",
    "\n",
    "\n",
    "class InvertedResidualConfig:\n",
    "    # Stores information listed at Tables 1 and 2 of the MobileNetV3 paper\n",
    "    def __init__(self, input_channels: int, kernel: int, expanded_channels: int, out_channels: int, use_se: bool,\n",
    "                 activation: str, stride: int, dilation: int, width_mult: float):\n",
    "        self.input_channels = self.adjust_channels(input_channels, width_mult)\n",
    "        self.kernel = kernel\n",
    "        self.expanded_channels = self.adjust_channels(expanded_channels, width_mult)\n",
    "        self.out_channels = self.adjust_channels(out_channels, width_mult)\n",
    "        self.use_se = use_se\n",
    "        self.use_hs = activation == \"HS\"\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    @staticmethod\n",
    "    def adjust_channels(channels: int, width_mult: float):\n",
    "        return _make_divisible(channels * width_mult, 8)\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    # Implemented as described at section 5 of MobileNetV3 paper\n",
    "    def __init__(self, cnf: InvertedResidualConfig, norm_layer: Callable[..., nn.Module],\n",
    "                 se_layer: Callable[..., nn.Module] = SqueezeExcitation):\n",
    "        super().__init__()\n",
    "        if not (1 <= cnf.stride <= 2):\n",
    "            raise ValueError('illegal stride value')\n",
    "\n",
    "        self.use_res_connect = cnf.stride == 1 and cnf.input_channels == cnf.out_channels\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        activation_layer = nn.Hardswish if cnf.use_hs else nn.ReLU\n",
    "\n",
    "        # expand\n",
    "        if cnf.expanded_channels != cnf.input_channels:\n",
    "            layers.append(ConvBNActivation(cnf.input_channels, cnf.expanded_channels, kernel_size=1,\n",
    "                                           norm_layer=norm_layer, activation_layer=activation_layer))\n",
    "\n",
    "        # depthwise\n",
    "        stride = 1 if cnf.dilation > 1 else cnf.stride\n",
    "        layers.append(ConvBNActivation(cnf.expanded_channels, cnf.expanded_channels, kernel_size=cnf.kernel,\n",
    "                                       stride=stride, dilation=cnf.dilation, groups=cnf.expanded_channels,\n",
    "                                       norm_layer=norm_layer, activation_layer=activation_layer))\n",
    "        if cnf.use_se:\n",
    "            layers.append(se_layer(cnf.expanded_channels))\n",
    "\n",
    "        # project\n",
    "        layers.append(ConvBNActivation(cnf.expanded_channels, cnf.out_channels, kernel_size=1, norm_layer=norm_layer,\n",
    "                                       activation_layer=nn.Identity))\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "        self.out_channels = cnf.out_channels\n",
    "        self._is_cn = cnf.stride > 1\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        result = self.block(input)\n",
    "        if self.use_res_connect:\n",
    "            result += input\n",
    "        return result\n",
    "\n",
    "\n",
    "class MobileNetV3(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            inverted_residual_setting: List[InvertedResidualConfig],\n",
    "            last_channel: int,\n",
    "            num_classes: int = 1000,\n",
    "            block: Optional[Callable[..., nn.Module]] = None,\n",
    "            norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "            **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        MobileNet V3 main class\n",
    "        Args:\n",
    "            inverted_residual_setting (List[InvertedResidualConfig]): Network structure\n",
    "            last_channel (int): The number of channels on the penultimate layer\n",
    "            num_classes (int): Number of classes\n",
    "            block (Optional[Callable[..., nn.Module]]): Module specifying inverted residual building block for mobilenet\n",
    "            norm_layer (Optional[Callable[..., nn.Module]]): Module specifying the normalization layer to use\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if not inverted_residual_setting:\n",
    "            raise ValueError(\"The inverted_residual_setting should not be empty\")\n",
    "        elif not (isinstance(inverted_residual_setting, Sequence) and\n",
    "                  all([isinstance(s, InvertedResidualConfig) for s in inverted_residual_setting])):\n",
    "            raise TypeError(\"The inverted_residual_setting should be List[InvertedResidualConfig]\")\n",
    "\n",
    "        if block is None:\n",
    "            block = InvertedResidual\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = partial(nn.BatchNorm2d, eps=0.001, momentum=0.01)\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "\n",
    "        # building first layer\n",
    "        firstconv_output_channels = inverted_residual_setting[0].input_channels\n",
    "        layers.append(ConvBNActivation(3, firstconv_output_channels, kernel_size=3, stride=2, norm_layer=norm_layer,\n",
    "                                       activation_layer=nn.Hardswish))\n",
    "\n",
    "        # building inverted residual blocks\n",
    "        for cnf in inverted_residual_setting:\n",
    "            layers.append(block(cnf, norm_layer))\n",
    "\n",
    "        # building last several layers\n",
    "        lastconv_input_channels = inverted_residual_setting[-1].out_channels\n",
    "        lastconv_output_channels = 6 * lastconv_input_channels\n",
    "        layers.append(ConvBNActivation(lastconv_input_channels, lastconv_output_channels, kernel_size=1,\n",
    "                                       norm_layer=norm_layer, activation_layer=nn.Hardswish))\n",
    "\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lastconv_output_channels, last_channel),\n",
    "            nn.Hardswish(inplace=True),\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(last_channel, num_classes),\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        x = self.features(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor, x_supp: Tensor, threshold: float) -> Tensor:\n",
    "        # get features\n",
    "        query = self._forward_impl(x)\n",
    "        if x_supp is None:\n",
    "            return query\n",
    "        \n",
    "        support = self._forward_impl(x_supp)\n",
    "\n",
    "        # compute the distance between support and query images\n",
    "        distance = torch.sum((query - support)**2, dim=-1)\n",
    "        probs = torch.softmax(-distance, dim=0)\n",
    "\n",
    "        # prob is not smalller than the threshold or not?\n",
    "        if torch.max(probs) < threshold:\n",
    "            return torch.tensor(data=-111)\n",
    "\n",
    "        return torch.argmax(probs)\n",
    "\n",
    "def _mobilenet_v3_conf(arch: str, width_mult: float = 1.0, reduced_tail: bool = False, dilated: bool = False,\n",
    "                       **kwargs: Any):\n",
    "    reduce_divider = 2 if reduced_tail else 1\n",
    "    dilation = 2 if dilated else 1\n",
    "\n",
    "    bneck_conf = partial(InvertedResidualConfig, width_mult=width_mult)\n",
    "    adjust_channels = partial(InvertedResidualConfig.adjust_channels, width_mult=width_mult)\n",
    "\n",
    "    if arch == \"mobilenet_v3_large\":\n",
    "        inverted_residual_setting = [\n",
    "            bneck_conf(16, 3, 16, 16, False, \"RE\", 1, 1),\n",
    "            bneck_conf(16, 3, 64, 24, False, \"RE\", 2, 1),  # C1\n",
    "            bneck_conf(24, 3, 72, 24, False, \"RE\", 1, 1),\n",
    "            bneck_conf(24, 5, 72, 40, True, \"RE\", 2, 1),  # C2\n",
    "            bneck_conf(40, 5, 120, 40, True, \"RE\", 1, 1),\n",
    "            bneck_conf(40, 5, 120, 40, True, \"RE\", 1, 1),\n",
    "            bneck_conf(40, 3, 240, 80, False, \"HS\", 2, 1),  # C3\n",
    "            bneck_conf(80, 3, 200, 80, False, \"HS\", 1, 1),\n",
    "            bneck_conf(80, 3, 184, 80, False, \"HS\", 1, 1),\n",
    "            bneck_conf(80, 3, 184, 80, False, \"HS\", 1, 1),\n",
    "            bneck_conf(80, 3, 480, 112, True, \"HS\", 1, 1),\n",
    "            bneck_conf(112, 3, 672, 112, True, \"HS\", 1, 1),\n",
    "            bneck_conf(112, 5, 672, 160 // reduce_divider, True, \"HS\", 2, dilation),  # C4\n",
    "            bneck_conf(160 // reduce_divider, 5, 960 // reduce_divider, 160 // reduce_divider, True, \"HS\", 1, dilation),\n",
    "            bneck_conf(160 // reduce_divider, 5, 960 // reduce_divider, 160 // reduce_divider, True, \"HS\", 1, dilation),\n",
    "        ]\n",
    "        last_channel = adjust_channels(1280 // reduce_divider)  # C5\n",
    "    elif arch == \"mobilenet_v3_small\":\n",
    "        inverted_residual_setting = [\n",
    "            bneck_conf(16, 3, 16, 16, True, \"RE\", 2, 1),  # C1\n",
    "            bneck_conf(16, 3, 72, 24, False, \"RE\", 2, 1),  # C2\n",
    "            bneck_conf(24, 3, 88, 24, False, \"RE\", 1, 1),\n",
    "            bneck_conf(24, 5, 96, 40, True, \"HS\", 2, 1),  # C3\n",
    "            bneck_conf(40, 5, 240, 40, True, \"HS\", 1, 1),\n",
    "            bneck_conf(40, 5, 240, 40, True, \"HS\", 1, 1),\n",
    "            bneck_conf(40, 5, 120, 48, True, \"HS\", 1, 1),\n",
    "            bneck_conf(48, 5, 144, 48, True, \"HS\", 1, 1),\n",
    "            bneck_conf(48, 5, 288, 96 // reduce_divider, True, \"HS\", 2, dilation),  # C4\n",
    "            bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, \"HS\", 1, dilation),\n",
    "            bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, \"HS\", 1, dilation),\n",
    "        ]\n",
    "        last_channel = adjust_channels(1024 // reduce_divider)  # C5\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type {}\".format(arch))\n",
    "\n",
    "    return inverted_residual_setting, last_channel\n",
    "\n",
    "\n",
    "def _mobilenet_v3_model(\n",
    "    arch: str,\n",
    "    inverted_residual_setting: List[InvertedResidualConfig],\n",
    "    last_channel: int,\n",
    "    pretrained: bool,\n",
    "    progress: bool,\n",
    "    **kwargs: Any\n",
    "):\n",
    "    model = MobileNetV3(inverted_residual_setting, last_channel, **kwargs)\n",
    "    if pretrained:\n",
    "        if model_urls.get(arch, None) is None:\n",
    "            raise ValueError(\"No checkpoint is available for model type {}\".format(arch))\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def mobilenet_v3_large(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> MobileNetV3:\n",
    "    \"\"\"\n",
    "    Constructs a large MobileNetV3 architecture from\n",
    "    `\"Searching for MobileNetV3\" <https://arxiv.org/abs/1905.02244>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    arch = \"mobilenet_v3_large\"\n",
    "    inverted_residual_setting, last_channel = _mobilenet_v3_conf(arch, **kwargs)\n",
    "    return _mobilenet_v3_model(arch, inverted_residual_setting, last_channel, pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def mobilenet_v3_small(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> MobileNetV3:\n",
    "    \"\"\"\n",
    "    Constructs a small MobileNetV3 architecture from\n",
    "    `\"Searching for MobileNetV3\" <https://arxiv.org/abs/1905.02244>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    arch = \"mobilenet_v3_small\"\n",
    "    inverted_residual_setting, last_channel = _mobilenet_v3_conf(arch, **kwargs)\n",
    "    return _mobilenet_v3_model(arch, inverted_residual_setting, last_channel, pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "model_tiny = mobilenet_v3_large(pretrained=True)\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "ts_model = torch.jit.script(model_tiny)\n",
    "optimized_torchscript_model = optimize_for_mobile(ts_model)\n",
    "optimized_torchscript_model.save(\"mobilenetv3_large.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}